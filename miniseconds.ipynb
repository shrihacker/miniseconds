{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a79e23-d530-41da-9e49-3d381d510856",
   "metadata": {},
   "source": [
    "# Imports & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fb33e35-9c9c-4a9b-9699-52ca585a304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import replicate\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "import instructor\n",
    "from pytube import YouTube\n",
    "from typing_extensions import Annotated\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import Field, BaseModel, AfterValidator\n",
    "from google.cloud import storage\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from nltk import tokenize\n",
    "\n",
    "# Set your environment variables. see .env.example\n",
    "load_dotenv() \n",
    "client = storage.Client()\n",
    "o_client = instructor.patch(OpenAI())\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587d7a9-9858-4137-8e12-0a9194f2519d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e15e591d-b749-48ee-b96b-5e780cafef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = string.ascii_lowercase + string.digits\n",
    "def random_choice():\n",
    "    '''\n",
    "    Return a 8 letter random string\n",
    "    '''\n",
    "    return ''.join(random.choices(alphabet, k=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2633e96b-032c-43c4-9d12-e5c44c6af23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_bucket(blob_name, file_path):\n",
    "    '''\n",
    "    Upload a file to Google Cloud Storage\n",
    "        Input: blob_name: String, name of Blob on GCS\n",
    "               file_path: String, path to local file to upload\n",
    "        Output: public URL: String, of the uploaded blob\n",
    "    '''\n",
    "    bucket = client.get_bucket(os.getenv('GCS_BUCKET'))\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_filename(file_path)\n",
    "    return blob.public_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "68bc05a8-bf1b-4d4a-adf5-8540626bb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(url, fname):\n",
    "    '''\n",
    "    Replicate Deployment call to fetch transcript.\n",
    "    Writes out the transcript JSON and text to files\n",
    "        Input: url: String, of the uploaded blob\n",
    "               fname: String, filename to write out JSON and text files\n",
    "        Output: out: dictionary, output of transcript call with timestamps\n",
    "                concatenated_text: String, full transcript text\n",
    "    '''\n",
    "    out = replicate.run(\n",
    "    \"daanelson/whisperx:9aa6ecadd30610b81119fc1b6807302fd18ca6cbb39b3216f430dcf23618cedd\",\n",
    "    input={\"audio\": url, \"batch_size\": 16, \"align_output\": True}\n",
    "    )\n",
    "\n",
    "    # Write out the JSON transcript\n",
    "    fp = open(f\"{data_dir}/{fname}.json\", \"w\")\n",
    "    fp.write(json.dumps(out))\n",
    "\n",
    "    # Write out the text transcript\n",
    "    concatenated_text = \" \".join(item['text'] for item in out)\n",
    "    fp = open(f\"{data_dir}/{fname}.txt\", \"w\")\n",
    "    fp.write(concatenated_text)\n",
    "\n",
    "    return out, concatenated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90c2b878-0be3-40ac-a642-5854ff97c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube(yt_link, fname):\n",
    "    '''\n",
    "    Download a Youtube Video and write out a unique mp4 and mp3 file\n",
    "    Input: yt_link: String, URL of youtube video\n",
    "               fname: String, filename to write out Audio and Video files\n",
    "    Output: out: audio_path: String path to MP3 audio file \n",
    "                 video_path: String path to MP4 video file\n",
    "    '''\n",
    "    fname = f\"{data_dir}/{fname}.mp4\"\n",
    "    yt = YouTube(yt_link)\n",
    "    video_path = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first().download(filename=fname)\n",
    "    audio_path = video_path.replace(\".mp4\", \".mp3\")\n",
    "    cmd = f\"ffmpeg -i {video_path} -vn {audio_path} -hide_banner -loglevel error\"\n",
    "    os.system(cmd)\n",
    "    return audio_path, video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7e1884f-4b60-4bcf-b16d-5db685c0da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size, overlap):\n",
    "    \"\"\"\n",
    "    Splits a text into chunks with a specified size and overlap.\n",
    "\n",
    "    Input:\n",
    "    text (str): The text to be chunked.\n",
    "    chunk_size (int): The size of each chunk in words.\n",
    "    overlap (int): The number of words to overlap between consecutive chunks.\n",
    "\n",
    "    Output:\n",
    "    list: A list of text chunks.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk = ' '.join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # Overlap words for the next chunk\n",
    "\n",
    "        # Break the loop if we reach the end of the text\n",
    "        if end >= len(words):\n",
    "            break\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8eb714ed-c12d-43e6-800f-94b44d4cea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timestamps(json_data, sentence):\n",
    "    \"\"\"\n",
    "    Finds the start and end timestamps of a specific sentence within a given JSON data structure.\n",
    "\n",
    "    The function searches for the first 20 characters of the sentence at the beginning and the last 20 characters \n",
    "    at the end within the 'text' field of each JSON object. When the start of the sentence is found, it records \n",
    "    the 'start' timestamp. It continues to search for the end of the sentence, and when found, records the 'end' \n",
    "    timestamp of the last word that matches. The search is case-insensitive.\n",
    "\n",
    "    Parameters:\n",
    "    json_data (list of dicts): A list of dictionaries, each containing 'text' and 'words' fields, \n",
    "                               where 'words' is a list of dicts with 'word' and 'end' fields.\n",
    "    sentence (str): The sentence for which the start and end timestamps are to be found.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple (start_time, end_time) where both are timestamps. 'start_time' is the timestamp \n",
    "           when the sentence starts, and 'end_time' is the timestamp when the sentence ends. \n",
    "           Returns (None, None) if the sentence is not found.\n",
    "    \"\"\"\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    start = sentence[:20]\n",
    "    end = sentence[-20:]\n",
    "    #print(f\"start: {start}, end: {end}\")\n",
    "    for item in json_data:\n",
    "        if start.lower() in item['text'].lower():\n",
    "            #print(item['text'])\n",
    "            start_time = item['start']\n",
    "        if start_time and end.lower() in item['text'].lower():\n",
    "            #print(item['text'])\n",
    "            end_words = end.split(\" \")\n",
    "            end_w = end_words[-1]\n",
    "            item_words = item['words']\n",
    "            for i_w in item_words:\n",
    "                #print(f\"i_w = {i_w}\")\n",
    "                ip_w = i_w['word'].translate(str.maketrans('', '', string.punctuation))\n",
    "                end_w = end_w.translate(str.maketrans('', '', string.punctuation))\n",
    "                #print(f\"ip_w = {ip_w}\")\n",
    "                if end_w == ip_w:\n",
    "                    end_time = i_w['end']\n",
    "                    break\n",
    "        if start_time is not None and end_time is not None:\n",
    "            break\n",
    "\n",
    "    return start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "87069639-c30c-44cc-a732-f776ee76b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quote(BaseModel):\n",
    "    '''\n",
    "    A quote is a sentence or few sentences extracted verbatim from a long transcript.\n",
    "    Quotes are interesting because they may be insightful or funny or contrarian or a punchline.\n",
    "    Quotes are valuable because they create great social media engagement.\n",
    "    A quote is also independent & standalone and doesnt need context defined before it to be consumed.\n",
    "    They are entites that can be understood without needing the transcript\n",
    "    '''\n",
    "    quote: str\n",
    "\n",
    "class Section(BaseModel):\n",
    "    '''\n",
    "    A transcript string is long and can contain many topics spoken at length in sequence.\n",
    "    A section represents the summary of a subset of the transcript\n",
    "    We have Top 10 Quotes that can be part of a single Section. There can be fewer than 10 but no more than 10\n",
    "    There are usually many Sections in a transcript.\n",
    "    '''\n",
    "    section: str\n",
    "    quotes: List[Quote]\n",
    "\n",
    "class AllSections(BaseModel):\n",
    "    '''\n",
    "    All Sections found are part of a List\n",
    "    '''\n",
    "    sections : List[Section]\n",
    "    \n",
    "# class TranscriptClip(BaseModel):\n",
    "#     '''\n",
    "#     A Clip is a small sequential monologue or dialogue that is extracted from a long transcript which may be an interview or podcast.\n",
    "#     A Clip can qualify for short form standalone engaging content.\n",
    "#     '''\n",
    "#     #clip : Annotated[str, AfterValidator(clip_length_check)] = Field(description=\"An engaging clip extracted verbatim from a long transcript\")\n",
    "#     clip : str = Field(description=\"An engaging clip extracted verbatim from a long transcript\")\n",
    "    \n",
    "# class AllClips(BaseModel):\n",
    "#     '''\n",
    "#     A List of TranscriptClips\n",
    "#     '''\n",
    "#     clips: List[TranscriptClip]\n",
    "\n",
    "def get_quotes(transcript):\n",
    "    \"\"\"\n",
    "    Extracts engaging clips from a given transcript for social media content.\n",
    "\n",
    "    The function utilizes a GPT-4 model to analyze the transcript and extract relevant clips. \n",
    "\n",
    "    Parameters:\n",
    "    transcript (str): The long text input, such as a transcript of a talk, interview, or podcast.\n",
    "\n",
    "    Returns:\n",
    "    AllSections: A list of Sections found and many Quotes for each Section\n",
    "    \"\"\"\n",
    "    sections = o_client.chat.completions.create(\n",
    "      model=\"gpt-4-0125-preview\",\n",
    "      response_model= AllSections,\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": transcript}\n",
    "      ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=4095,\n",
    "        max_retries=3\n",
    "    )\n",
    "    return sections.model_dump_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ace61-1e18-448c-ad7b-8361a5da90ae",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8107a570-ea29-47a7-80cc-f6c65d0cf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Generate a random name, and fetch a Youtube video's MP4 and MP3 with that name\n",
    "fname = random_choice()\n",
    "audio_path, video_path = get_youtube(\"https://youtu.be/3EJHMoh3Q1k?si=bjug0g2Ynis3rGh4\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3458662d-0cfa-4203-99ee-2f496132763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 : Upload the audio path to the storage bucket and get its transcript\n",
    "url = upload_to_bucket(f\"{fname}.mp3\", audio_path)\n",
    "out, concatenated_text = get_transcript(url, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "74e379a8-91e2-4b09-9d68-0093426df0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get Quotes from the transcript\n",
    "oai_response = get_quotes(concatenated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6de0b025-36f1-4285-b901-72920ef9439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sections\":[{\"section\":\"Introduction\",\"quotes\":[{\"quote\":\"Today, a successful man and a thorough contrarian. Why everything you thought you knew about business may very well be wrong. Peter Thiel, Uncommon Knowledge, now.\"},{\"quote\":\"Welcome to Uncommon Knowledge. I'm Peter Robinson.\"},{\"quote\":\"A co-founder of PayPal, a co-founder of Palantir, the president of Clarium Capital, a managing partner in the Founders Fund, and the first outside investor in Facebook, Peter Thiel is one of Silicon Valley's leading investors, one of its leading thinkers, and since finding himself portrayed in the movie The Social Network, one of its leading celebrities.\"},{\"quote\":\"You can't escape it now. The son of German immigrants, Mr. Thiel grew up just up the road in Foster City, California. After majoring in philosophy as a Stanford undergraduate, he attended Stanford Law School, which is where he and I first became friends. Before returning to California to begin his career in business, Mr. Thiel practiced law briefly.\"},{\"quote\":\"How long were you at Cravath? Sullivan and Cromwell. Sullivan and Cromwell, interchangeable. Seven months and three days.\"},{\"quote\":\"Mr. Thiel's new book, Zero to One, Notes on Startups or How to Build the Future. Peter Thiel, welcome.\"}]},{\"section\":\"Zero to One: Horizontal vs. Vertical Progress\",\"quotes\":[{\"quote\":\"0 to 1. I'm quoting the book now. If you take one typewriter and build 100, you have made horizontal progress. If you have a typewriter and build a word processor, you have made vertical process. Explain.\"},{\"quote\":\"Well, I think in the 21st century, we're going to have two basic modes of progress. One is globalization, which is basically about copying things that work, and the other one involves technology or inventing new things. And that's what Zero to One is about. It's everything I know about how we build the great new companies that will take our civilization to the next level in the century ahead.\"},{\"quote\":\"In Zero to One, you discuss China. You consider that an exemplar of globalization.\"},{\"quote\":\"all they're doing is copying things that have already existed. On the other hand, it's quite powerful. Look what China has been able to do, lift hundreds of millions out of poverty and yet you say, quote, most people think the future of the world will be defined by globalization. The truth is that technology matters more.\"},{\"quote\":\"China's plan for the next 20 years is very straightforward. It is just to copy everything that works in the West. It's not that they can't invent new things. I think they might be able to. I don't think there's anything about Chinese culture that intrinsically makes it impossible for people to invent new things, but they don't really have to because it's still very poor and they can get a lot from just copying things that work. But for the so-called developed nations, U.S., Western Europe, Japan, we actually do have to invent new things. And that's why for us, technology matters a lot more than globalization.\"}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(oai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10bc5f-8265-421f-bb60-26f17efc80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract the clips\n",
    "clip_dict = json.loads(oai_response)\n",
    "clip_list = clip_dict[\"clips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edc1af-78d3-4459-a9ac-79ccdeb5699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a14e3-588f-4800-a152-8c0ea1cfc6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Clip it!\n",
    "count = 0\n",
    "for c in clip_list:\n",
    "    s_t , e_t = find_timestamps(out, c['clip'])\n",
    "    #print(f\"found {s_t} and {e_t}\\n\\n\")\n",
    "    if s_t and e_t:\n",
    "        cmd = f\"ffmpeg -y -ss {s_t} -to {e_t} -i {video_path}  -c copy {data_dir}/{fname}_clipped_{count}.mp4 -hide_banner -loglevel error\"\n",
    "        os.system(cmd)\n",
    "        count = count+1\n",
    "    else:\n",
    "        print(f\"Couldnt find {c['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f107b-acb5-41c2-8538-bd408988a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
